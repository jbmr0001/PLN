{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiewiqJVPI6D"
      },
      "source": [
        "# **Procesamiento del Lenguaje Natural**\n",
        "## *Práctica 2 - Preprocesamiento de un texto*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s88tBCmhPmMD"
      },
      "source": [
        "### Objetivos de esta práctica:\n",
        "\n",
        "\n",
        "1.   Conocer la librería NLTK\n",
        "2.   Aprender a preprocesar un texto.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMTAs5WJQE5h"
      },
      "source": [
        "### ¿Qué es **NLTK**? \n",
        "\n",
        "[NLTK](http://www.nltk.org/) es una librería muy potente para el lenguaje de programación Python que proporciona interfaces para utilizar fácilmente una gran cantidad de recursos léxicos, así como métodos para el procesamiento, análisis y clasificación de textos. \n",
        "\n",
        "Los creadores de esta herramienta escribieron un libro, en el que realizan una introducción práctica a la programación para el procesamiento del lenguaje, que puede seros de gran utilidad y que se encuentra en el siguiente enlace: http://www.nltk.org/book/."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HFMyVWJQosI"
      },
      "source": [
        "#### 1. Instalando NLTK en notebook\n",
        "\n",
        "Este notebook tiene algunas dependencias, la mayoría de las cuales se pueden instalar a través del gestor de paquetes de python `pip`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucZaAklAQ369",
        "outputId": "12fdcd93-c434-4de2-e460-bca033b1ff79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqTAibyxQS_e"
      },
      "source": [
        "### Preprocesamiento de un texto\n",
        "\n",
        "En esta práctica vamos a ver los principales pasos a realizar para preprocesar la información de un texto empleando la librería NLTK.\n",
        "\n",
        "Para ello lo primero que debemos hacer es importar la librería que queremos utilizar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjzqTRAWQN5z",
        "outputId": "d212fec8-2a5e-4f67-a98d-b1ba7d2c0fde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g11TpIIjQbsr"
      },
      "source": [
        "#### 1. División del texto en oraciones\n",
        "\n",
        "El primer paso consiste en separar el texto en oraciones. Para ello, la librería NLTK proporciona la función: \n",
        "\n",
        "```\n",
        "sent_tokenize(text, language='english')\n",
        "```\n",
        "\n",
        "Esta función, divide en oraciones el texto pasado como argumento utilizando el  idioma que queremos analizar. Esta función utiliza un modelo de lenguaje incluyendo caracteres que marcan el inicio y el fin de una oración, y están disponibles para 17 lenguas europeas (español, inglés, holandés, francés...). \n",
        "Por defecto, si no se especifica ningún idioma, se utiliza el modelo en inglés. \n",
        "\n",
        "Veamos un ejemplo. En primer lugar, importamos la función *sent_tokenize* y después la llamamos pasándole como argumento el texto que queremos dividir. El tipo de dato que devuelve es una lista con las oraciones del texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pti_1PXvRPKK"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import sent_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7fyrXL5S0ED",
        "outputId": "44d21532-b9e4-4f7d-962b-095e69d93d97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Esto es una sentencia de prueba, ¿ésta sería la segunda sentencia?',\n",
              " 'Y la tercera.',\n",
              " '¡Me encanta la 4!']"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Esto es una sentencia de prueba, ¿ésta sería la segunda sentencia? Y la tercera. ¡Me encanta la 4!\"\n",
        "sent_tokenize(text, language=\"spanish\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pPgRchiGWS7B"
      },
      "source": [
        "Existen distintas formas de separar las sentencias, por ejemplo, usando la función *sent_tokenize* la coma está incluida dentro de la sentencia inicial."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnb-iPMZVdo9"
      },
      "source": [
        "#### 2. División de las oraciones en palabras (tokenization)\n",
        "\n",
        "Una vez separado el texto en oraciones vamos a ver cómo dividir una oración en palabras, concretamente en tokens. La forma básica de tokenización consiste en separar el texto en tokens por medio de espacios y signos de puntuación. Para ello, nosotros vamos a utilizar el tokenizador *TreebankWordTokenizer* ([aunque hay muchos más](https://www.nltk.org/api/nltk.tokenize.html)).\n",
        "\n",
        "Lo primero que debemos hacer será importar el tokenizador y posteriomente instanciar la clase."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kjwtrrTVuFR"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import TreebankWordTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xT0zvqq6VvWf"
      },
      "outputs": [],
      "source": [
        "tokenizer = TreebankWordTokenizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fi2BubCV9c1",
        "outputId": "b913fce7-78bb-4c5c-c0bd-f08d7c65b460"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Esto',\n",
              " 'es',\n",
              " 'una',\n",
              " 'sentencia',\n",
              " 'de',\n",
              " 'prueba',\n",
              " ',',\n",
              " '¿ésta',\n",
              " 'sería',\n",
              " 'la',\n",
              " 'segunda',\n",
              " 'sentencia',\n",
              " '?',\n",
              " 'Y',\n",
              " 'la',\n",
              " 'tercera.',\n",
              " '¡Me',\n",
              " 'encanta',\n",
              " 'la',\n",
              " '4',\n",
              " '!']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"Esto es una sentencia de prueba, ¿ésta sería la segunda sentencia? Y la tercera. ¡Me encanta la 4!\"\n",
        "tokenizer.tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXbibxKoW-1e"
      },
      "source": [
        "NLTK proporciona otros tokenizadores como *RegexpTokenizer*, *WhitespaceTokenizer*, *SpaceTokenizer*, *WordPunctTokenizer*, etc, que deberéis probar para completar los ejercicios de esta práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZGqPHHMXStT"
      },
      "source": [
        "#### 3. Eliminación de palabras vacías (stop words)\n",
        "\n",
        "Las palabras vacías (stop words) son palabras que carecen de significado por sí solas. Suelen ser artículos, pronombres, preposiciones... \n",
        "\n",
        "En algunas tareas del Procesamiento del Lenguaje Natural resulta útil eliminar dichas palabras, por lo que a continuación vamos a ver cómo podríamos eliminar las palabras vacías que forman parte de un conjunto de tokens. \n",
        "\n",
        "NLTK cuenta con una lista de palabras vacías para diferentes idiomas. Veamos cómo se utiliza:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmsyNDFlWBvN"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvuciEsaXpWO"
      },
      "outputs": [],
      "source": [
        "spanish_stops = stopwords.words('spanish')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR97XkAvbxDy"
      },
      "source": [
        "Como podemos ver, Python nos arroja un error indicando que no encuentra el paquete *stopwords*. Por lo tanto debemos descargarlo en NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV0DUvNVXtUj",
        "outputId": "a0f298de-b0f9-48e4-c8af-01aafa47adae"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZtCS6cHcFZl"
      },
      "source": [
        "Ahora si podemos hacer uso de este paquete y ver las *stopwords* incluidas para el español:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fDte3XWb96H",
        "outputId": "7b94a42b-8fb3-42f4-a637-733804b2df4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo', 'como', 'más', 'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí', 'porque', 'esta', 'entre', 'cuando', 'muy', 'sin', 'sobre', 'también', 'me', 'hasta', 'hay', 'donde', 'quien', 'desde', 'todo', 'nos', 'durante', 'todos', 'uno', 'les', 'ni', 'contra', 'otros', 'ese', 'eso', 'ante', 'ellos', 'e', 'esto', 'mí', 'antes', 'algunos', 'qué', 'unos', 'yo', 'otro', 'otras', 'otra', 'él', 'tanto', 'esa', 'estos', 'mucho', 'quienes', 'nada', 'muchos', 'cual', 'poco', 'ella', 'estar', 'estas', 'algunas', 'algo', 'nosotros', 'mi', 'mis', 'tú', 'te', 'ti', 'tu', 'tus', 'ellas', 'nosotras', 'vosotros', 'vosotras', 'os', 'mío', 'mía', 'míos', 'mías', 'tuyo', 'tuya', 'tuyos', 'tuyas', 'suyo', 'suya', 'suyos', 'suyas', 'nuestro', 'nuestra', 'nuestros', 'nuestras', 'vuestro', 'vuestra', 'vuestros', 'vuestras', 'esos', 'esas', 'estoy', 'estás', 'está', 'estamos', 'estáis', 'están', 'esté', 'estés', 'estemos', 'estéis', 'estén', 'estaré', 'estarás', 'estará', 'estaremos', 'estaréis', 'estarán', 'estaría', 'estarías', 'estaríamos', 'estaríais', 'estarían', 'estaba', 'estabas', 'estábamos', 'estabais', 'estaban', 'estuve', 'estuviste', 'estuvo', 'estuvimos', 'estuvisteis', 'estuvieron', 'estuviera', 'estuvieras', 'estuviéramos', 'estuvierais', 'estuvieran', 'estuviese', 'estuvieses', 'estuviésemos', 'estuvieseis', 'estuviesen', 'estando', 'estado', 'estada', 'estados', 'estadas', 'estad', 'he', 'has', 'ha', 'hemos', 'habéis', 'han', 'haya', 'hayas', 'hayamos', 'hayáis', 'hayan', 'habré', 'habrás', 'habrá', 'habremos', 'habréis', 'habrán', 'habría', 'habrías', 'habríamos', 'habríais', 'habrían', 'había', 'habías', 'habíamos', 'habíais', 'habían', 'hube', 'hubiste', 'hubo', 'hubimos', 'hubisteis', 'hubieron', 'hubiera', 'hubieras', 'hubiéramos', 'hubierais', 'hubieran', 'hubiese', 'hubieses', 'hubiésemos', 'hubieseis', 'hubiesen', 'habiendo', 'habido', 'habida', 'habidos', 'habidas', 'soy', 'eres', 'es', 'somos', 'sois', 'son', 'sea', 'seas', 'seamos', 'seáis', 'sean', 'seré', 'serás', 'será', 'seremos', 'seréis', 'serán', 'sería', 'serías', 'seríamos', 'seríais', 'serían', 'era', 'eras', 'éramos', 'erais', 'eran', 'fui', 'fuiste', 'fue', 'fuimos', 'fuisteis', 'fueron', 'fuera', 'fueras', 'fuéramos', 'fuerais', 'fueran', 'fuese', 'fueses', 'fuésemos', 'fueseis', 'fuesen', 'sintiendo', 'sentido', 'sentida', 'sentidos', 'sentidas', 'siente', 'sentid', 'tengo', 'tienes', 'tiene', 'tenemos', 'tenéis', 'tienen', 'tenga', 'tengas', 'tengamos', 'tengáis', 'tengan', 'tendré', 'tendrás', 'tendrá', 'tendremos', 'tendréis', 'tendrán', 'tendría', 'tendrías', 'tendríamos', 'tendríais', 'tendrían', 'tenía', 'tenías', 'teníamos', 'teníais', 'tenían', 'tuve', 'tuviste', 'tuvo', 'tuvimos', 'tuvisteis', 'tuvieron', 'tuviera', 'tuvieras', 'tuviéramos', 'tuvierais', 'tuvieran', 'tuviese', 'tuvieses', 'tuviésemos', 'tuvieseis', 'tuviesen', 'teniendo', 'tenido', 'tenida', 'tenidos', 'tenidas', 'tened']\n"
          ]
        }
      ],
      "source": [
        "spanish_stops = stopwords.words('spanish')\n",
        "print(spanish_stops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60nalenXcTJF"
      },
      "source": [
        "A continuación, dada una lista de palabras o tokens, vamos a filtrarlos para quitar aquellas palabras que son consideradas *stopwords*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5gsKQYHRcCpO",
        "outputId": "a4c05d30-7386-4278-b71a-d11b155610b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Esto', 'sentencia', 'prueba', ',', '¿ésta', 'segunda', 'sentencia', '?', 'Y', 'tercera.', '¡Me', 'encanta', '4', '!']\n"
          ]
        }
      ],
      "source": [
        "words = ['Esto', 'es', 'una', 'sentencia', 'de', 'prueba', ',', '¿ésta', 'sería', 'la', 'segunda', 'sentencia', '?', 'Y', 'la', 'tercera.', '¡Me', 'encanta', 'la', '4', '!']\n",
        "filtered = [word for word in words if word not in spanish_stops]\n",
        "print(filtered)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_D_WJHvcyM2"
      },
      "source": [
        "#### 4. Reducción de las palabras a su raíz (stemming)\n",
        "\n",
        "Stemming es la técnica utilizada para eliminar los afijos de una palabra con el objetivo de obtener su raíz. Por ejemplo, la raíz de “biblioteca” es “bibliotec”. \n",
        "\n",
        "Este método se suele utilizar en los sistemas de recuperación de información para la indexación de palabras ya que, en lugar de almacenar todas las formas de una palabra, permite almacenar sólo las raíces, reduciendo el tamaño del índice y mejorando el resultado. \n",
        "\n",
        "Existen diferentes algoritmos de stemming: Porter Stemmer, Lancaster Stemmer, Snowball Stemmer... \n",
        "\n",
        "NLTK cuenta con una implementación de algunos de estos algoritmos que son muy fáciles de utilizar. Simplemente hay que instanciar la clase, por ejemplo, *PorterStemmer* y llamar al método *stem()* con la palabra para la cual deseamos obtener su raíz. \n",
        "\n",
        "A continuación, vamos a ver un ejemplo sobre cómo obtener las raíces de una lista de tokens utilizando el algoritmo *Snowball*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyVl700XdZcH"
      },
      "outputs": [],
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tKO6C3Rd7d_"
      },
      "outputs": [],
      "source": [
        "stemmer = SnowballStemmer(\"spanish\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsvwPucfd8ko",
        "outputId": "d91a378d-4d55-417b-e5e5-6d5039512ee1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corr\n",
            "bibliotec\n",
            "aburr\n"
          ]
        }
      ],
      "source": [
        "print(stemmer.stem(\"corriendo\"))\n",
        "print(stemmer.stem(\"biblioteca\"))\n",
        "print(stemmer.stem(\"aburridos\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fClmznfegbY"
      },
      "source": [
        "## Ejercicios\n",
        "\n",
        "El resultado de esta primera práctica deberá entregarse en PLATEA. Se entregará este mismo notebook de extensión *.ipynb* y se renombrará de la siguiente forma: pr2_usuario.ipynb. Sustituye \"usuario\" por el alias de vuestro correo.\n",
        "\n",
        "\n",
        "Para el desarrollo de estos ejercicios, debeis hacer uso de la colección de documentos de [SciELO](https://scielo.org/es/) disponible en PLATEA en la carpeta \"Material Complementario\" llamado \"colección_SciELO_PLN\".\n",
        "\n",
        "Esta colección está compuesta por 25 ficheros en formato XML. Debéis realizar el tratamiento de cada fichero y tener en cuenta el texto incluido en la etiqueta  **<dc:description xml:lang=\"es\">**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Realizado por:** Juan Bautista Muñoz Ruiz jbmr0001@red.ujaen.es"
      ],
      "metadata": {
        "id": "9c0zPa0LoaAO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK-cub2Nhqmv"
      },
      "source": [
        "### Ejercicio 1\n",
        "\n",
        "Crear un método que divida en oraciones los textos, haciendo uso de la función\n",
        "*sent_tokenize*. La función mostrará el número medio de oraciones por cada fichero analizado, el nombre del fichero que contiene menos sentencias y el nombre del fichero que contiene más sentencias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iARF5hizxBBr",
        "outputId": "80b2183b-67c9-4d00-a3e7-bf25a668f8d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive  #Montamos el drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ur9SYjPbxUNf",
        "outputId": "bc54555f-d38d-4614-eb65-70f745127c3c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/PLN/colección_SciELO_PLN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import os #Abrimos la carpeta\n",
        "path = os.chdir(\"/content/drive/MyDrive/PLN/colección_SciELO_PLN\")\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4W-YOVqEhOJN",
        "outputId": "fbb9c080-287b-4052-e599-9d033c8a9b35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "S0211-69952009000500011.xml Introducción: Los resultados de los trasplantes efectuados con donantes con criterios expandidos (DCE) son inferiores a los obtenidos con donantes con criterios estándar (DCS). Para optimizar su evolución, se podría reducir su tiempo de isquemia fría (TIF) reduciendo su daño de preservación. Comparamos los resultados obtenidos al aplicar TIF < 15 horas tanto a DCE como a DCS. Material y métodos: Realizamos un estudio unicéntrico, de cohortes, prospectivo, de casos incidentes de trasplante renal de cadáver entre junio de 2003 y diciembre de 2007. El tiempo mínimo de seguimiento fue de 12 meses. Comparamos los datos de los donantes, de los receptores y de la evolución de los trasplantes efectuados con DCE frente a los de los DCS. Resultados: El TIF para los DCE (N = 24) y para los DCS (N = 50) fue, respectivamente, de 9,3 ± 2,5 y 8,3 ± 3,3 horas (p = 0,18). No encontramos diferencias significativas entre los receptores de DCE y DCS en cuanto a: no función primaria del injerto 4,2 vs. 4%, retardo en la función del injerto 16,7 vs. 10%, complicaciones quirúrgicas 25 vs. 16% y rechazos agudos 8,3 vs. 2%. El filtrado glomerular estimado al año para los DCS fue de 65,8 ± 14,9 ml/min y para los DCE de 49,4 ± 12,5 ml/min (p < 0,0001). La supervivencia renal al año fue del 95,8% para los receptores de DCE y del 94% para los DCS (p = 0,75). Conclusiones: La aplicación de TIF cortos a los DCE permite conseguir una evolución similar a la de los DCS, aunque su función renal sea en todo momento inferior.\n",
            "S0211-69952009000600003.xml La peritonitis es una de las complicaciones más graves de la diálisis peritoneal. Las bacterias son las responsables de la mayoría de los casos. La infección fúngica es infrecuente, pero se asocia con una alta morbilidad, con la imposibilidad de continuar en el programa de diálisis y con un importante índice de mortalidad. Su incidencia varía del 1% al 10% de los episodios de peritonitis en niños y del 1% al 23% en adultos. Su presentación clínica es similar a la de la peritonitis bacteriana. Los factores predisponentes de peritonitis fúngica no han sido establecidos con claridad; los episodios previos de peritonitis bacteriana y el tratamiento con antibióticos de amplio espectro han sido descritos a menudo en la literatura. Las especies de Candida son los patógenos más habituales y Candida albicans la más frecuente, pero en la última década se ha observado una alta prevalencia de Candida parapsilosis. El diagnóstico microbiológico es fundamental para determinar la etiología y prescribir el tratamiento, que suele requerir, además de la terapia antifúngica, la retirada del catéter peritoneal y la consecuente transferencia a hemodiálisis. Fluconazol y anfotericina B son los antifúngicos recomendados; los nuevos fármacos como voriconazol y caspofungina han demostrado tener también una gran utilidad. El propósito de esta revisión sistemática ha sido analizar los aspectos clínicos y microbiológicos de la peritonitis fúngica, los cuales son poco conocidos y han cambiado en los últimos años.\n",
            "S0211-69952009000600011.xml La dislipemia es un reconocido factor de riesgo cardiovascular en la población general, pero no así en pacientes con enfermedad renal crónica (ERC). Los objetivos del presente estudio han sido determinar si las alteraciones lipídicas más comunes, así como las concentraciones de apolipoproteína (apo) A y B, son capaces de predecir la mortalidad y el desarrollo de nuevos episodios cardiovasculares (CV) en pacientes con ERC en estadios previos a la diálisis. Se trata de un estudio de observación prospectivo histórico en el que se incluyeron 331 pacientes con ERC en estadios 4-5 prediálisis. Se determinaron los siguientes parámetros lipídicos: colesterol total, triglicéridos, HDL, LDL, apo A-I y apo B. Se analizó la asociación de estas variables con la mortalidad global y con el desarrollo de episodios CV. La mediana de seguimiento fue 985 días, y durante este período hubo 105 fallecimientos y 54 nuevos episodios CV. En un modelo multivariable de Cox ajustado al resto de covariables de reconocida importancia pronóstica, la razón de riesgo (RR) por cada 10 mg/dl de apo A fue de 0,915 (IC 95%: 0,844 a 0,992; p = 0,031). Los pacientes con una relación apo A/apo B elevada (tercil superior, >1,42) también tuvieron una supervivencia significativamente mejor que la del resto de los pacientes estudiados (RR = 0,592, IC 95%: 0,3680-0,953; p <0,05). No hubo relación significativa entre los parámetros lipídicos y el desarrollo de episodios CV. En conclusión, las concentraciones de apo A y una relación apo A/apo B elevada se asocian con un mejor pronóstico vital en pacientes con ERC prediálisis.\n",
            "S0211-69952010000100007.xml Introducción: En los últimos años se ha mantenido estable el número de pacientes en lista de espera para un trasplante renal. El trasplante renal de donante vivo representa actualmente una vía para aumentar el pool de donantes, pero hay un grupo de pacientes que presentan incompatibilidad de grupo sanguíneo ABO, lo que contraindicaba hasta ahora que pudiera llevarse a cabo el trasplante. Nuestro objetivo consiste en describir nuestra experiencia con el programa de trasplante renal de donante vivo con incompatibilidad de grupo ABO. Material y métodos: Se trata de un estudio de retrospectivo-descriptivo de los primeros 11 pacientes sometidos a trasplante renal de donante vivo ABO incompatible en el Hospital Clínic de Barcelona desde octubre de 2006 a enero de 2009. Se utilizó un protocolo de acondicionamiento basado en inmunoadsorción específica (con número sesiones necesarias hasta conseguir títulos de isoaglutininas aceptables pretrasplante), inmunoglobulina policlonal inespecífica y anticuerpo monoclonal anti-CD20, seguido del tratamiento inmunosupresor adaptado a cada receptor. Se determinaron títulos de isoaglutininas antes del tratamiento de acondicionamiento, pretrasplante y postrasplante durante las primeras 2 semanas. La valoración inmunológica, médica y quirúrgica fue la habitual en el programa de trasplante renal de donante vivo. Resultados: La edad media de los donantes y receptores fue de 47,8 &plusmn; 12,4 y 44,4 &plusmn; 14,1 años, respectivamente. Un 90,1% de los donantes fue mujer y un 72,7% de los receptores, hombres. El tiempo de seguimiento medio fue de 10,2 &plusmn; 10,2 meses. Hermanos y esposos fueron las relaciones más frecuentes (n = 4, 36,4%, respectivamente), al igual que la causa de nefropatía fueron la glomerulopatía, poliquistosis y el síndrome de Alport (n = 2, 18,2% para cada enfermedad renal primaria). Todos los pacientes adquirieron un título de isoaglutininas correctos pretrasplante (<8) y requirieron 5,54 &plusmn; 2,6 sesiones de inmunoadsorción pretrasplante y 2,82 sesiones postrasplante. Un paciente no requirió ninguna sesión de inmunoadsorción (única con incompatibilidad anti-B) y otro requirió recambios plasmáticos, en vez de inmunoadsorciones, por tratarse de un potencial receptor hipersensibilizado con crossmatch por citometría de flujo positivo. Los títulos de isoaglutininas postrasplante se mantuvieron a títulos bajos. Dos pacientes presentaron un episodio de rechazo agudo celular (Banff IA e IB), con buena respuesta al tratamiento. La supervivencia de paciente y del injerto fue de un 90,9% en el primer año y se mantuvo estable a lo largo del seguimiento. Únicamente se registró una pérdida del injerto por fallecimiento en relación con una complicación hemorrágica en las primeras 72 horas sin relación con la incompatibilidad de grupo ABO. La función de injerto renal al año es excelente, con valores de creatinina sérica de 1,3 &plusmn; 0,8 mg/dl, con aclaramiento de creatinina ajustado a superficie corporal 62,6 ml/min/1,73 m² y proteinuria de 244,9 mg/orina de 24 horas. Conclusiones: El trasplante renal de donante vivo con incompatibilidad de grupo sanguíneo representa una alternativa eficaz y segura en determinados pacientes en lista de espera de trasplante renal, obteniendo resultados excelentes de supervivencia de paciente e injerto y con una buena función de injerto renal.\n",
            "S0211-69952009000600010.xml Objetivo: Estimar la calidad de vida en pacientes con enfermedad renal crónica, que no han recibido ni diálisis ni trasplante, y su asociación con factores de riesgo. Diseño: Estudio descriptivo transversal de una muestra representativa de pacientes de dos entidades promotoras de salud colombianas. Se aplicó el instrumento de medición de calidad de vida SF-36 y las puntuaciones se relacionaron con datos demográficos, clínicos y de laboratorio. Resultados: La mediana de edad fue 70 años, un 67% eran hombres, un 93% tenían hipertensión arterial y un 67% se encontraban en estadio 3. La medida de salud física de calidad de vida se vio más afectada que la medida de salud mental (Wilcoxon, p <0,001). Los dominios de función física, desempeño físico y dolor corporal se vieron menos afectados en hombres y en jóvenes. La salud física estuvo más relacionada con variables sociodemográficas y clínicas. Las personas con enfermedad renal crónica mayores de 65 años, mujeres y con diabetes presentaron una menor puntuación del componente físico. La salud mental tuvo un menor valor en las mujeres. Después de ajustar por edad, no se encontró asociación entre la tasa de filtración glomerular y la salud física. La calidad de vida es mejor en los hombres (p <0,001) y un 12,5% de la varianza de dicha diferencia se explica por la edad. Conclusiones: Los pacientes con enfermedad renal crónica sin diálisis ni trasplante presentan una mayor alteración de la calidad de vida que la población general, principalmente en el componente físico; las mujeres mayores de 65 años se vieron más afectadas.\n",
            "S0211-69952009000500014.xml La enfermedad celíaca se produce por la interacción entre el gluten contenido en los cereales y varios factores genéticos y autoinmunes. Aunque las manifestaciones clínicas predominantes son digestivas, se han descrito varias manifestaciones sistémicas. También se ha asociado con varias enfermedades renales, entre las que predominan las glomerulonefritis. Describimos el caso de una paciente con una enfermedad celíaca aparecida tras su primera gestación que de forma simultánea presenta proteinuria nefrótica y microhematuria, con sustrato morfológico de nefropatía membranosa. Tras recibir tratamiento con medidas conservadoras (IECA, estatina) y dieta sin gluten, se aprecia mejoría de la clínica digestiva, y desaparición de los anticuerpos antitransglutaminasa tisular tipo IgA y de la proteinuria. Revisamos la relación entre enfermedad celíaca y nefropatía membranosa y el papel de la dieta libre de gluten en el control de las mismas.\n",
            "S0211-69952009000500007.xml Introducción: La obesidad aumenta el riesgo de proteinuria e insuficiencia renal crónica, y acelera la progresión de enfermedades renales. En los pacientes obesos existe un aumento de la actividad del sistema renina-angiotensina-aldosterona (SRAA) y de los niveles de aldosterona. Ningún estudio ha comparado la eficacia de las diferentes estrategias antiproteinúricas actualmente disponibles (inhibidores de la enzima convertidora de la angiotensina [IECA], antagonistas de los receptores de la angiotensina [ARA], antagonistas de la aldosterona) en pacientes obesos con nefropatías proteinúricas. Métodos: Es un estudio prospectivo y aleatorizado, realizado en un único centro. Fueron seleccionados doce pacientes obesos (índice de masa corporal >30 kg/m²), con proteinuria >0,5 g/24 h, de nuestras consultas de Nefrología. Los pacientes fueron tratados consecutivamente durante seis semanas y en orden aleatorio con un IECA (lisinopril 20 mg/día), una terapia combinada con IECA más ARA (lisinopril 10 mg/día más candesartán 16 mg/día) y eplerenona (25 mg/día). Se estableció un período de lavado de seis semanas entre los diferentes períodos de tratamiento. El objetivo principal del estudio fue el cambio en la proteinuria de 24 h al final de cada período de tratamiento y el número de pacientes que mostraban una reducción de la proteinuria superior al 25% con respecto al valor basal. Resultados: La reducción de la proteinuria obtenida por lisinopril (11,3 ± 34,8%) no fue estadísticamente significativa con respecto al valor basal, mientras que la reducción con lisinopril y candesartán (26,9 ± 30,6%) y eplerenona (28,4 ± 31,6%) mostró una diferencia estadísticamente significativa frente a sus valores basales (comparación intragrupo) y frente al grupo de lisinopril (comparación entre grupos). El número de pacientes que mostraron una reducción mayor al 25% de la proteinuria fue significativamente mayor con eplerenona (67%) y lisinopril + candesartán (67%) que con lisinopril (25%). Conclusiones: La monoterapia con antagonistas de la aldosterona (eplerenona) y la terapia de combinación con IECA + ARA fueron más efectivos que los IECA en monoterapia para reducir la proteinuria en pacientes obesos con diferentes tipos de nefropatías crónicas proteinúricas.\n",
            "S0211-69952009000500008.xml Introducción: Para garantizar una adecuada continuidad de la asistencia de los pacientes que se dializan en centros de hemodiálisis extrahospitalarios concertados (CH), es fundamental que exista una estrecha relación y comunicación entre los propios CH y los hospitales de referencia (HR). El objetivo de este trabajo es conocer aspectos actuales de esta relación para detectar oportunidades de mejora. Material y métodos: Estudio transversal y descriptivo mediante dos encuestas autocumplimentadas, una dirigida a CH (81 preguntas) y otra a HR (56 preguntas), que abordaban distintos aspectos de la relación entre ambos. La encuesta se envió a través del correo electrónico disponible en la S.E.N. Resultados: Se recibió respuesta de 80 CH y 30 HR. De estos últimos, sólo 27 tenían relación con CH dependientes de su área. El 70% de los CH pertenecen a multinacionales y el 16% están ubicados dentro de un hospital. El 64% de los CH precisa la contratación de no nefrólogos para la asistencia. Casi un 40% de los nefrólogos de los CH hace guardias en los HR. Más de tres cuartas partes de los nefrólogos de los CH están solos durante toda su jornada laboral. Respecto a la relación entre ambos tipos de centros, es frecuente la comunicación telefónica bidireccional. Alrededor de un tercio de los pacientes remitidos al centro desde el hospital no aporta serologías actualizadas ni tiene un acceso vascular definitivo realizado. La remisión del paciente desde el centro al hospital suele ser muy completa, con pruebas actualizadas e informe completo. El 41,3% de los CH refería haber sido consultado por el HR con relación a toma de decisiones acerca de sus pacientes. Las analíticas y pruebas complementarias de protocolo en el CH vienen predefinidas por el concierto en el 65% de los casos, pero pueden ser modificadas en su mayoría por los propios centros, siendo consensuadas entre ambos en más de la mitad de los casos. El 60% de los CH puede pedir directamente interconsultas con otros especialistas, pero más de la mitad precisa del nefrólogo del HR para hacerlo. En su mayor parte, la medicación parenteral es suministrada al centro por el HR, pero más de un tercio de los centros tiene limitaciones para solicitar al HR dedicación parenteral de uso hospitalario menos común o no especificada en el concierto. Los HR refieren que la mayoría de los accesos vasculares se realiza en el propio hospital, mientras que los CH refieren que esto ocurre sólo en la mitad de los casos. En más de una tercera parte, las fístulas de pacientes en prediálisis se realizan en el centro como colaboración con el HR. La mayoría de los centros puede intervenir en la decisión de inclusión de sus pacientes en la lista de espera de trasplante. En sólo la quinta parte existe una base de datos común entre el CH y el HR, y menos de la mitad comparte protocolos de actuación u objetivos comunes. El 62,5% de los centros participa en ensayos clínicos conjuntos con el HR. Más de la mitad de las empresas proporciona formación a sus CH, ya sea directamente por la propia empresa o facilitando la asistencia a jornadas congresos. Conclusiones: Algunos de los aspectos que parecen manifiestamente mejorables son: la soledad de los nefrólogos de los CH y su acceso limitado a la formación; la adecuada remisión de los pacientes de los HR a los centros; la autonomía de los nefrólogos a la hora de solicitar interconsultas a especialistas sin precisar de la tutela de los nefrólogos del hospital; o la limitación a la hora de acceder a la medicación de uso hospitalario. Una estrecha relación entre CH y HR es de gran importancia para asegurar una mejor y más equitativa asistencia a nuestros pacientes. La creación de un foro de debate favorecería la puesta en común y la resolución de estos aspectos.\n",
            "S0211-69952009000600012.xml La timoglobulina forma parte del esquema de inmunosupresión en receptores de trasplante renal de alto riesgo inmunológico. Hemos comparado, en un estudio observacional y prospectivo, la incidencia de rechazo agudo, de infecciones oportunistas y de neoplasias, así como la supervivencia del injerto y del receptor, entre un grupo de 50 receptores de alto riesgo inmunológico con tratamiento de inducción que incluía timoglobulina, frente a un grupo de bajo riesgo cuyos 50 receptores recibieron injertos procedentes de los mismos donantes, en nuestro hospital en el período 2002-2006. El grupo de alto riesgo estaba formado por receptores hiperinmunizados (>50%), retrasplantes con pérdida de injerto previa inmunológica, reactividad en prueba cruzada, raza negra, o alta incompatiblidad HLA. La inmunosupresión consistió en administrar timoglobulina a dosis que mantuvieran un recuento de linfocitos T inferior a 10 µl, FK a partir del día 5, micofenolato mofetil y esteroides, y los pacientes recibían profilaxis frente al CMV con ganciclovir. El grupo de bajo riesgo incluía los pacientes sin estas características, a quienes se les realizaba la inmunosupresión con ciclosporina A, micofenolato mofetil y prednisona. Todos los receptores seronegativos con donantes seropositivos recibieron valganciclovir durante 100 días. Se descartaron aquellos pacientes en quienes se perdió el injerto por causas técnicas en el postoperatorio inmediato, junto con sus parejas. En todos los receptores se llevó a cabo un seguimiento mínimo de un año posterior al trasplante, con una mediana de 41,7 meses. Los dos grupos eran homogéneos en cuanto a edad y sexo del donante, edad del receptor e incompatibilidades HLA, pero el porcentaje de receptores varones era significativamente superior en el grupo control. El porcentaje de retrasplantes y de receptores hiperinmunizados fue significativamente superior en el grupo de alto riesgo, de acuerdo con los criterios de selección del grupo. La incidencia de rechazo agudo histológicamente probado fue superior en el grupo control (el 30 frente al 6%; p =0,003) y no se han producido diferencias significativas en cuanto a la incidencia de infecciones oportunistas ni de neoplasias; se ha diagnosticado un caso de leucemia aguda y un caso de enfermedad linfoproliferativa en el grupo de bajo riesgo. La supervivencia de los pacientes fue del 97,9% en ambos grupos al año y a los 3 años, mientras que la supervivencia del injerto fue del 89,8 y del 84,8% en el grupo de alto riesgo frente al 93,8 y al 90,4% en el grupo sin riesgo al año y a los 3 años (p = NS). En nuestra experiencia, la evolución de receptores de trasplante renal con alto riesgo inmunológico es similar a la del grupo de riesgo normal mientras se utilice una inmunosupresión lo suficientemente potente, que condicionó una incidencia de rechazo agudo significativamente menor en el grupo de alto riesgo.\n",
            "S0211-69952009000500009.xml Objetivos: Determinar la frecuencia y tipo de alteraciones de la función tiroidea en niños con insuficiencia renal crónica (IRC) en programa de diálisis peritoneal (DP) o hemodiálisis (HD), así como establecer la utilidad de bocio como marcador clínico para identificar pacientes con IRC que cursan con alteraciones de la función tiroidea. Pacientes y métodos: Estudio transversal y descriptivo, realizado en un hospital pediátrico de tercer nivel de atención. Se incluyeron pacientes menores de 17 años, con IRC y con más de tres meses en DP o HD. En cada paciente se evaluó su crecimiento y desarrollo, así como la presencia de bocio. Las alteraciones tiroideas se detectaron mediante la cuantificación de los niveles séricos de tirotropina (TSH), tiroxina (T4L) y triyodotironina (T3T). Resultados: Se incluyeron 50 pacientes, 25 del sexo masculino, con edad promedio de 3 años. Hubo 14 (28%) pacientes con alteración en la función tiroidea, nueve con hipotiroidismo subclínico, tres con síndrome de enfermo eutiroideo y dos con hipotiroidismo primario. En 13 pacientes se detectó bocio, siete con disfunción tiroidea y seis con función normal. La sensibilidad del bocio para la detección de alteraciones tiroideas fue del 50%, y la especificidad del 83.3%. Dos de los pacientes con hipotiroidismo presentaron la mayor afectación en su crecimiento. Conclusiones: Debido a la alta frecuencia de alteraciones tiroideas en niños con IRC, es necesaria su valoración de manera sistemática, a fin de mejorar la calidad de su atención.\n",
            "S0211-69952009000500013.xml Objetivos: determinar la prevalencia y gravedad de hiperplasia gingival en un grupo de pacientes con trasplante renal (TR) y analizar el efecto del uso de los inmunosupresores ciclosporina A (CsA), tacrolimus (Tac), sirolimus (Siro) y azatioprina (Aza) o micofenolato de mofetilo (MMF) sobre esta complicación. Métodos: se clasificó la presencia y gravedad de la hiperplasia gingival. Se analizó el impacto de los medicamentos inmunosupresores, edad, higiene bucal, verapamilo y nifedipina sobre esta complicación mediante regresión logística múltiple. Resultados: fueron 172 pacientes. Usaban CsA 137, Tac 25, Siro 6, Aza 107 y MMF 56. Tuvieron hiperplasia gingival el 59,1% con CsA, 12,0% con Tac, y 16,7% con Siro. Aumentaron la frecuencia de hiperplasia gingival CsA con razón de momios (RM) 15,2, edad < 45 años con RM 5,6 y mala higiene bucal con RM 3,2, y la disminuyeron Aza con RM 0,05 y MMF con RM 0,03. Conclusiones: Aza y MMF ofrecieron protección significativa contra el desarrollo de hiperplasia gingival en este grupo de pacientes con TR.\n",
            "S0211-69952009000500002.xml El factor de crecimiento de tejido conectivo (CTGF) aparece aumentado en diferentes patologías asociadas a fibrosis, incluidas múltiples enfermedades renales. CTGF participa en procesos biológicos, como la regulación del ciclo celular, migración, adhesión y angiogénesis. Su expresión está regulada por diversos factores implicados en el daño renal, entre los que destacan el factor la angiotensina II, el factor de crecimiento transformante-beta, altas concentraciones de glucosa y situaciones de estres celular. CTGF participa en el inicio y progresión del daño renal al ser capaz de inducir una respuesta inflamatoria y promover la fibrosis, señalándole como una posible diana terapéutica en el tratamiento de patologías renales. En este trabajo revisamos las principales acciones de CTGF en la patología renal, los mecanismos intracelulares de actuación y las estrategias terapéuticas para su bloqueo.\n",
            "S0211-69952009000600013.xml La poliquistosis renal autosómica dominante (PQRAD) es una enfermedad hereditaria multiorgánica, caracterizada por un progresivo crecimiento y desarrollo de quistes renales que destruyen el parénquima funcional. Es responsable del 7-10% de los casos de insuficiencia renal crónica terminal que precisan tratamiento renal sustitutivo, causada por mutaciones en los genes PKD1 y PKD2. Las dos formas de PQRAD tienen una patogenia y clínica similar, pero en los pacientes con mutación en PKD2, las manifestaciones clínicas aparecen más tarde y la progresión a nefropatía terminal acontece 10 años más tarde que en los pacientes con mutación en PKD1. El diagnóstico de esta enfermedad puede realizarse fácilmente mediante ecografía, pero el diagnóstico molecular ofrece la ventaja de la detección precoz de individuos asintomáticos portadores del defecto genético. En este trabajo, presentamos los resultados del análisis genético (PKD2) de 18 pacientes diagnosticados de PQRAD. Los objetivos de nuestro trabajo fueron comparar la rentabilidad del estudio genético respecto al radiológico, realizar un diagnóstico genético precoz en los descendientes de pacientes afectados, e intentar establecer una correlación fenotipo-genotipo en los pacientes con mutación en PKD2. Tras el análisis genético, sólo se diagnosticó a una familia (5,56 %) con mutación en el exón 13 del gen PKD2, consistente en una sustitución del nucleótido adenosina por citosina (c.2398A>C) que implicaba el cambio del aminoácido metionina por leucina (p.800Met>Leu). En nuestra población, contrariamente a lo publicado, la mutación sí se segregó con la enfermedad, y todos los miembros con diagnóstico clínico y de imagen de PQRAD presentaron dicha mutación. Dada la alta prevalencia de insuficiencia renal crónica e insuficiencia renal crónica terminal secundaria a poliquistosis renal en nuestro medio, el diagnóstico genético precoz de la poliquistosis renal conllevaría mejor pronóstico en relación con un seguimiento clínico más estricto.\n",
            "S0211-69952010000100004.xml Las patologías renal y cardíaca asociadas son de alta prevalencia en la población en diferentes contextos clínicos: fracaso renal agudo en el contexto de insuficiencia cardíaca (IC) descompensada, pacientes con IC que desarrollan enfermedad renal crónica (ERC) o pacientes con ERC que desarrollan IC. En los últimos años se ha descrito el síndrome cardiorrenal (SCR) como el deterioro de la función renal en el contexto de IC. Sin embargo, existen otras situaciones clínicas en las que la Nefrología puede aportar su conocimiento como parte de la estrategia de tratamiento integral, como es el caso de la IC refractaria (ICR). Todas estas situaciones obligan a un trabajo conjunto interdisciplinario entre cardiólogos y nefrólogos con el fin de proporcionar un tratamiento integral. Este documento pretende hacer una revisión del papel del nefrólogo en el tratamiento de la IC haciendo hincapié en el subgrupo de pacientes con ICR y la evidencia actual de la utilidad de la diálisis peritoneal (DP) como tratamiento crónico coadyuvante.\n",
            "S0211-69952010000100006.xml En este estudio presentamos todos los resultados derivados del procesamiento de los datos del registro de los pacientes de diálisis peritoneal que iniciaron tratamiento sustitutivo en Andalucía entre enero de 1999 y diciembre de 2008. Toda la información procede del Sistema de Información de la Coordinación Autonómica de Trasplante de Andalucía (SICATA). Se presentan datos demográficos, distribución por provincias, las causas de insuficiencia renal y motivo de elección de la diálisis peritoneal como técnica de tratamiento renal sustitutivo, la situación con respecto al trasplante, datos en relación con el catéter y técnica de diálisis peritoneal, las salidas del programa y sus causas, las peritonitis del año 2008, su evolución y resultado de los cultivos. Presentamos también en el informe datos evolutivos 1999-2008 en cuanto a inclusiones, diabetes, tratamiento con diálisis peritoneal automática e incidencia de peritonitis. Analizamos, por otra parte, la supervivencia global de los pacientes y de la técnica diálisis peritoneal, la comorbilidad al inicio del tratamiento y su impacto en la supervivencia.\n",
            "S0211-69952010000100008.xml Antecedentes: Diversos estudios han demostrado la eficacia de darbepoetina alfa (DA) administrada quincenalmente (C2S), lo que permite simplificar el tratamiento para la anemia, pero faltan datos acerca de la evolución del índice de resistencia (IRE) tras el espaciamiento desde una frecuencia semanal (CS) en la práctica clínica. Material y métodos: Estudio observacional, multicéntrico, retrospectivo, con 16 semanas de seguimiento, en pacientes dializados estables convertidos de DA CS a C2S. El espaciamiento se realizó según ficha técnica (duplicación de dosis semanal). El cálculo del IRE fue: dosis DA (&micro;g/sem.kg*200)/Hb (g/dl). Se analizó la evolución del IRE mediante un ANOVA multivariado de medidas repetidas, ajustando por variables confusoras. Resultados: Se reclutaron 202 pacientes (137 en hemodiálisis [HD], DA intravenosa, y 65 con diálisis peritoneal [DP], DA subcutánea). La edad media (DE) fue 66 (17) años, y el 61% eran hombres. Se apreció una gran variabilidad intercentro en el IRE basal (coeficiente de variación del 88%, p <0,001 para diferencias entre centros). En el análisis univariado los factores predictores de IRE elevado fueron un bajo nivel de albúmina, la HD, o los antecedentes de enfermedad cardiovascular. Durante el seguimiento, el IRE aumentó ligeramente en los pacientes con HD (9,3 [8,4] basal frente a 11,1 [7,3] a 16 semanas; p <0,05), y se mantuvo estable en los pacientes con DP (6,8 [4,6] frente a 6,7 [4,0], respectivamente; NS). En el análisis multivariado, tras ajustar por los niveles de albúmina y el centro, el IRE global no presentó cambios significativos (media [IC 95%] basal de 10,0 [8,7-11,4] frente a 10,5 [9,3-11,8] a las 16 semanas, cambio ajustado de +0,5 [-0,67; 1,67]; NS). Conclusiones: La conversión de frecuencia semanal a quincenal de DA logró mantener el IRE, con independencia del tipo de diálisis. El análisis multivariado refleja que, una vez ajustado por las variables centro y estado de inflamación/nutricional del paciente, no hay cambios en el IRE en las primeras 16 semanas tras el espaciamiento.\n",
            "S0211-69952009000500006.xml La respuesta inmunitaria a la vacuna de la hepatitis B (HB) está impedida en los pacientes en hemodiálisis (HD), y la persistencia de la inmunidad, la eficacia de la revacunación y la periodicidad de la realización de controles serológicos no están bien definidas. Presentamos la experiencia de un protocolo de vacunación de la HB con tres dosis intramusculares de 40 µg de vacuna recombinante (Engerix®-B) en un grupo de 136 pacientes atendidos en una unidad de HD a lo largo de 18 años. Se realizaron controles anuales de anticuerpos anti-HB en todos los pacientes, y semestrales en 31; y se administraba anualmente una dosis doble de vacuna a los pacientes que no respondían o cuando los niveles de anticuerpos descendían por debajo de 10 UI/ml. Setenta y cuatro pacientes (54,4%) presentaron seroconversión, mientras que 62 pacientes no respondieron. La edad de los pacientes era superior en el grupo de no respondedores, pero no se observaron diferencias en el sexo ni en la etiología de la enfermedad renal. Un 32% de los pacientes respondedores perdió la memoria inmunológica al primer año de la vacunación, y tan sólo un 18% de los pacientes permaneció inmunizado a los seis años. El título de anticuerpos inmediatamente después de completar la vacunación fue predictor del mantenimiento de la memoria inmunológica: un 75% de los pacientes con títulos de anticuerpos >1.000 UI/ml mantuvo la seroprotección a los tres años en comparación con un 47% con títulos entre 100-999 (p = 0,08), y un 34% con títulos entre 11-99 (p = 0,02). La administración de dosis de refuerzo fue efectiva en un 24% de los pacientes no respondedores, y un 69% mantenía la respuesta inmunológica al final del primer año. Las dosis de refuerzo repetidas en pacientes no respondedores a una primera dosis consiguieron nuevas seroconversiones en un 19,6% de los pacientes. La práctica de controles semestrales podría haber permitido administrar dosis de recuerdo antes del período anual en un 16% de los pacientes respondedores. En conclusión, nuestros resultados demuestran que un protocolo de vacunación de la HB con un seguimiento serológico regular y dosis de refuerzo sucesivas consigue una aceptable seroprotección en los pacientes en hemodiálisis.\n",
            "S0211-69952009000600006.xml En junio de 2009, la OMS declaró la pandemia por virus de la influenza A de origen porcino (H1N1). Desde entonces, los nefrólogos fuimos afectados en varias de nuestras actividades. Disminuyó la asistencia al trabajo del personal de salud al cuidado de pacientes renales crónicos. Aparecieron nuevos casos de fallo renal agudo asociados a la infección viral, la mayoría en adultos jóvenes, con alta tasa de mortalidad. Hubo contagios en pacientes trasplantados renales y se retrajo transitoriamente la procuración de órganos en la semanas de mayor contagio. Entidades científicas se movilizaron para consensuar protocolos de evaluación y tratamiento con el fin de disminuir el impacto de la pandemia en pacientes renales.\n",
            "S0211-69952009000600004.xml El magnesio es el catión extracelular más abundante en el cuerpo humano y el segundo más abundante intracelular después del potasio. Es esencial para la transferencia, almacenamiento y utilización de la energía como regulador y catalizador de más de 300 sistemas enzimáticos. La hipomagnesemia puede producir una variedad de anormalidades metabólicas y consecuencias clínicas. Puede resultar del desequilibrio entre la absorción intestinal y la excreción renal. La principal consecuencia relacionada directamente con la hipomagnesemia son las arritmias cardiovasculares por hipopotasemia secundaria, y si no se reconoce y trata puede ser fatal. En este artículo revisamos las hipomagnesemias haciendo hincapié en los mecanismos moleculares responsables de la homeostasis del magnesio, diagnóstico diferencial y tratamiento, a propósito de la descripción de las manifestaciones clínicas y bioquímicas y el defecto genético en una familia afectada de síndrome de Gitelman.\n",
            "S0211-69952009000500010.xml Objetivo: analizar las características del fracaso renal agudo (FRA) en nuestro centro y determinar su influencia en el pronóstico del mismo y en la mortalidad. Material y métodos: estudio retrospectivo de los episodios de FRA valorados por nuestro Servicio durante un período de dos años (2005-2007). Los criterios de inclusión fueron: elevación de la creatinina sérica 0,5 mg/dl en pacientes con función renal previa normal y de 1 mg/dl en aquéllos con insuficiencia renal crónica previa. Se registraron factores epidemiológicos, clínicos, analíticos, terapéuticos y pronósticos. Resultados: valoramos 201 episodios de FRA. El 62,7% 16,38 (63,68% ±) eran varones. La edad media fue de 67,35 > 65 años). El índice de comorbilidad de Charlson (ICCH) mostraba unos valores de 3,49 ± 2,43. Ciento quince pacientes tenían IRC previa al ingreso. El 52,7% fueron prerrenales, el 34,8% parenquimatosos y el 8,5% obstructivos. El 35,8% cursaron con oligoanuria. El tiempo medio de ingreso fue de 22,47 ± 21,3 días. El 70,1% de los pacientes recuperaron función renal al alta. La mortalidad fue del 30,8%. En el estudio univariante se asociaron significativamente con la mortalidad (p < 0,05): ICCH, oliguria, hipoalbuminemia, niveles bajos de colesterol y anemia. En el análisis de regresión lineal múltiple, los factores que mejor la explicaban fueron: ICCH, oliguria y niveles bajos de colesterol. Realizamos un modelo predictivo de mortalidad con estos factores. Conclusión: la mayor complejidad clínica basal de los pacientes, el desarrollo de oliguria y la presencia de datos de malnutrición-inflamación aparecen como los principales factores pronósticos y de mortalidad en el FRA que valoramos los nefrólogos en el momento actual.\n",
            "S0211-69952009000500015.xml Presentamos dos casos de infección por Strongyloides stercoralis (S. stercoralis) en pacientes trasplantados renales en nuestro centro. Se describen las características de su presentación clínica, el tratamiento y la resolución del mismo.\n",
            "S0211-69952009000600015.xml La leucemia mieloide crónica (LMC) es una enfermedad mieloproliferativa caracterizada por la expansión clonal de células mieloides que expresan la proteína de fusión BCR-ABL, responsable de los efectos oncogénicos de la LMC. La terapia actual en el tratamiento de LMC es el inhibidor de la BCR-ABL tirosín-kinasa, imatinib. Aunque este fármaco ha demostrado mejorar la supervivencia en pacientes con LMC, su papel en el contexto del trasplante renal no ha sido ampliamente descrito en la literatura. Presentamos un caso de remisión molecular de LMC en un varón de 55 años con un segundo trasplante renal, hepatitis C y con riesgos cardiovasculares e inmunológicos asociados.\n",
            "S0211-69952009000500012.xml Introducción: El estrés oxidativo es crucial para el desarrollo de arteriosclerosis, principal causa de morbimortalidad en población en prediálisis. Nuestro objetivo fue valorar la oxidación de las principales líneas moleculares y discernir si algún biomarcador tenía mejor comportamiento valorando este estrés. Pacientes y método: Estudio observacional en 32 pacientes con MDRD 22,1 ± 1,08 ml/min. Medimos en linfocitos periféricos: malondialdehído, glutatión oxidado/reducido, 8-oxo-deoxiguanosina nuclear y mitocondrial, superóxido dismutasa, glutatión reductasa, glutatión peroxidasa y catalasa, y en plasma F2 isoprostanos y proteínas carboniladas. Correlacionamos los resultados con función renal y factores comórbidos. Resultados: Todos los biomarcadores tuvieron amplias diferencias significativas cuando se compararon con el grupo control peroxidación lipídica: F2 isoprostanos: 821,89 ± 300,47 ng/ml vs. 270 (95,66)* ng/ml (p < 0,000); MDA 0,11 (0,11)* vs. 0,7 ± 0,31 nmol/mg prot (p < 0,000). Oxidación proteica: GSSG/GSH: 6,89 ± 1,91 vs. 1,39 ± 0,75 (p < 0,000); proteínas carboniladas: 7,41 ± 0,84 vs. 3,63 (1,12)*. Daño material genético: 8-oxo-deoxiguanosina nuclear: 7,88 (2,32)* vs. 2,96 (1,78)* y 8-oxo-dG mitocondrial: 15,73 ± 2,28 vs. 13,85 ± 1.44 (p < 0,05). Los valores de las enzimas antioxidantes también obtuvieron amplias diferencias significativas. La molécula 8-oxodeoxiguanosina en DNA nuclear fue la que tuvo una relación significativa con el resto de biomarcadores, con homocisteína (r = 0,305; p < 0,05), lipoproteína (a) (r = 0,375; p < 0,01), 8-oxo-deoxiguanosina mitocondrial (r = 0,411; p < 0,05), GSSG/GSH (r = 0,595; p < 0,001) y proteínas carboniladas (r = 0,489; p < 0,05), y de forma inversa con las proteínas totales (r = -0,247; p < 0,01), GSH (r = -0,648; p < 0,000), GRS (r = -0,563; p < 0,001) y SOD (-0,497; p < 0,000). Ninguno de los parámetros tuvo correlación con la función renal. Tampoco se obtuvieron diferencias significativas con la presencia o no de diabetes o la toma de estatinas. * Mediana (amplitud intercuartil). Conclusión: Existe un elevado estrés oxidativo en los pacientes con enfermedad renal avanzada que probablemente se establezca desde fases tempranas de la enfermedad. Entre todos los parámetros estudiados, la molécula de 8-oxo-dG se comportó como el marcador más idóneo.\n",
            "S0211-69952009000600009.xml Antecedentes: La peritonitis fúngica es una complicación infrecuente pero grave en pacientes en diálisis peritoneal continua ambulatoria (DPCA). Métodos: Durante un período de 10 años (1999-2008), de un total de 175 pacientes con insuficiencia renal crónica en tratamiento con DPCA, estudiamos retrospectivamente 10 casos de peritonitis fúngica, analizando los factores predisponentes, aspectos clínicos, agentes etiológicos y tratamiento. El diagnóstico se estableció por la presencia de efluente peritoneal turbio con recuento superior a 100 leucocitos/µl y aislamiento de hongos en el cultivo microbiológico. Resultados: La peritonitis fúngica representó un 3,6% del total de peritonitis. Nueve pacientes tenían historia de peritonitis bacteriana previa y todos habían recibido antibioterapia. Otros hallazgos destacables fueron: edad superior a 70 años (50%) y diabetes mellitus (40%). El examen microscópico del líquido peritoneal fue de utilidad para sospechar la infección en 6 pacientes (60%). Los agentes responsables de peritonitis fueron: Candida parapsilosis (4), C. albicans (2), C. tropicalis (1), C. glabrata (1), C. famata (1) y Fusarium oxysporum (1). Los antifúngicos utilizados en el tratamiento fueron: fluconazol intraperitoneal y oral, vorizonazol intravenoso y oral y anfotericina B intravenosa. A consecuencia de la infección fúngica, 8 pacientes fueron transferidos a hemodiálisis. Un paciente murió antes de ser diagnosticado y otros tres durante el episodio de peritonitis. Conclusiones: Los pacientes con episodios de peritonitis bacteriana previos y tratamiento antibiótico presentaron un mayor riesgo de desarrollar peritonitis fúngica. C. parapsilosis fue el patógeno más frecuente. El tratamiento antifúngico junto con la retirada del catéter peritoneal fue eficaz en el 60% de los pacientes.\n",
            "S0211-69952009000600014.xml Introducción: Las alteraciones en el diafragma de filtración y/o citoesqueleto del podocito están relacionadas con proteinuria y síndrome nefrótico. En nuestra población, la glomerulopatía más frecuente, demostrada por biopsia, es la glomerulosclerosis focal y segmentaria. Nuestro objetivo fue buscar alteraciones en la expresión de algunas de las proteínas asociadas con el diafragma de filtración en pacientes con proteinuria en rango nefrótico. Métodos: Tejido renal de 40 pacientes con proteinuria en rango nefrótico, de 10 pacientes con proteinuria leve, de tres con hematuria aislada y 10 muestras de tejido renal normal (donantes cadáveres) se estudiaron, por inmunofluorescencia indirecta, para expresión de nefrina, podocina y alfa-actinina 4. Resultados: La expresión de estas proteínas fue lineal, homogénea, en las paredes capilares glomerulares del tejido renal normal y de pacientes con hematuria aislada. En proteinuria nefrótica y en algunos casos de proteinuria leve este aspecto normal estaba alterado y su expresión cambió de lineal a granular fina. En 22 casos (45%) de pacientes con proteinuria nefrótica y en 3 casos (30%) de pacientes con proteinuria subnefrótica hubo pérdida en la expresión de al menos una de estas proteínas (p = 0,49). Estas alteraciones se encontraron en las diferentes glomerulopatías que de forma más habitual causan síndrome nefrótico, aunque ninguna en particular fue significativamente más frecuente. Conclusiones: En la proteinuria nefrótica es muy frecuente la redistribución o la pérdida de proteínas asociadas al diafragma de filtración, lo que en muchos casos podría ser una consecuencia más que una causa de la proteinuria. Estas alteraciones pueden evidenciarse también en pacientes con proteinuria leve.\n"
          ]
        }
      ],
      "source": [
        "import glob   #Lectura y procesado de los archivos\n",
        "import xml.dom.minidom\n",
        "archivosProcesados=[]\n",
        "nombresArchivos=[]\n",
        "for filename in glob.glob('*.xml'):  #Lectura de todos los archivos de la carpeta con la libreria glob\n",
        "   with open(os.path.join(os.getcwd(), filename), 'r') as f:\n",
        "     nombresArchivos.append(filename)\n",
        "     doc = xml.dom.minidom.parseString(f.read())\n",
        "     texto=doc.getElementsByTagName('dc:description')  #Extraemos el contenido de las etiquetas description con la libreria xml.dom.minidom\n",
        "     \n",
        "     for element in texto:  \n",
        "          if element.getAttribute(\"xml:lang\") == \"es\": #Nos quedamos con las estiquetas con el atributo de idioma en español\n",
        "            archivosProcesados.append(element.firstChild.nodeValue); \n",
        "j=0\n",
        "for i in archivosProcesados: #Mostramos el nombre del archivo y el contenido leído\n",
        "  print(nombresArchivos[j],end=\" \")\n",
        "  print(i)\n",
        "  j=j+1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IneFuih1F6BS",
        "outputId": "2028aad7-aa2c-44fb-c6e0-18c06be9dd95"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.8/dist-packages (3.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from nltk) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from nltk) (4.64.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.8/dist-packages (from nltk) (2022.6.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.8/dist-packages (from nltk) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Nj4F0zdGCPy",
        "outputId": "1abe3b2b-fae1-4200-efcf-59d435db9ea4"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# función para calcular la media \n",
        "def media(): \n",
        "  i=0\n",
        "  suma=0\n",
        "  media=0\n",
        "  while i<len(numOraciones):  #\n",
        "    suma=suma+numOraciones[i]\n",
        "    i=i+1\n",
        "  \n",
        "  media=suma/len(numOraciones)\n",
        "  return media\n",
        "\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "oraciones=[] #Vector auxiliar para almacenar las oraciones de cada archivo tras tokenizar\n",
        "menor=2000\n",
        "mayor=-10\n",
        "indiceMayor=0\n",
        "indiceMenor=0\n",
        "i=0\n",
        "numOraciones=[] #Vector para almacenar el numero de oraciones de cada archivo\n",
        "for archivo in archivosProcesados:\n",
        "  oraciones=sent_tokenize(archivo, language=\"spanish\")\n",
        "  numOraciones.append(len(oraciones))  #Calculamos el número de oraciones de cada archivo con el tokenizer y lo almacenamos \n",
        "  print(\"Número de oraciones del archivo\",end=\" \")\n",
        "  print(nombresArchivos[i],end=\" \")\n",
        "  print(len(oraciones),end=\" \")\n",
        "\n",
        "  #Calculamos el menor y el mayor y vamos guardando el índice para mostrar la información al final\n",
        "  if len(oraciones)<menor:  \n",
        "    menor=len(oraciones)\n",
        "    indiceMenor=i\n",
        "  \n",
        "  if len(oraciones)>mayor:\n",
        "    mayor=len(oraciones)\n",
        "    indiceMayor=i\n",
        "  print(\"Media de oraciones actual:\",end=\" \")  #Mostramos la media con cada archivo leído\n",
        "  print(media())\n",
        "  i=i+1\n",
        "\n",
        "\n",
        "print(\"El archivo con menos oraciones es: \",end=\"\")\n",
        "print(nombresArchivos[indiceMenor],end=\"\")\n",
        "print(\" con\",end=\" \")\n",
        "print(menor)\n",
        "\n",
        "print(\"El archivo con más oraciones es: \",end=\"\")\n",
        "print(nombresArchivos[indiceMayor],end=\"\")\n",
        "print(\"con\",end=\" \")\n",
        "print(mayor,end=\" \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjy8_-L7GERo",
        "outputId": "389c7fdc-85f9-41c6-cfd9-767b4b410827"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de oraciones del archivo S0211-69952009000500011.xml 15 Media de oraciones actual: 15.0\n",
            "Número de oraciones del archivo S0211-69952009000600003.xml 10 Media de oraciones actual: 12.5\n",
            "Número de oraciones del archivo S0211-69952009000600011.xml 10 Media de oraciones actual: 11.666666666666666\n",
            "Número de oraciones del archivo S0211-69952010000100007.xml 19 Media de oraciones actual: 13.5\n",
            "Número de oraciones del archivo S0211-69952009000600010.xml 12 Media de oraciones actual: 13.2\n",
            "Número de oraciones del archivo S0211-69952009000500014.xml 6 Media de oraciones actual: 12.0\n",
            "Número de oraciones del archivo S0211-69952009000500007.xml 11 Media de oraciones actual: 11.857142857142858\n",
            "Número de oraciones del archivo S0211-69952009000500008.xml 26 Media de oraciones actual: 13.625\n",
            "Número de oraciones del archivo S0211-69952009000600012.xml 13 Media de oraciones actual: 13.555555555555555\n",
            "Número de oraciones del archivo S0211-69952009000500009.xml 11 Media de oraciones actual: 13.3\n",
            "Número de oraciones del archivo S0211-69952009000500013.xml 8 Media de oraciones actual: 12.818181818181818\n",
            "Número de oraciones del archivo S0211-69952009000500002.xml 5 Media de oraciones actual: 12.166666666666666\n",
            "Número de oraciones del archivo S0211-69952009000600013.xml 9 Media de oraciones actual: 11.923076923076923\n",
            "Número de oraciones del archivo S0211-69952010000100004.xml 5 Media de oraciones actual: 11.428571428571429\n",
            "Número de oraciones del archivo S0211-69952010000100006.xml 5 Media de oraciones actual: 11.0\n",
            "Número de oraciones del archivo S0211-69952010000100008.xml 13 Media de oraciones actual: 11.125\n",
            "Número de oraciones del archivo S0211-69952009000500006.xml 11 Media de oraciones actual: 11.117647058823529\n",
            "Número de oraciones del archivo S0211-69952009000600006.xml 6 Media de oraciones actual: 10.833333333333334\n",
            "Número de oraciones del archivo S0211-69952009000600004.xml 6 Media de oraciones actual: 10.578947368421053\n",
            "Número de oraciones del archivo S0211-69952009000500010.xml 18 Media de oraciones actual: 10.95\n",
            "Número de oraciones del archivo S0211-69952009000500015.xml 2 Media de oraciones actual: 10.523809523809524\n",
            "Número de oraciones del archivo S0211-69952009000600015.xml 4 Media de oraciones actual: 10.227272727272727\n",
            "Número de oraciones del archivo S0211-69952009000500012.xml 21 Media de oraciones actual: 10.695652173913043\n",
            "Número de oraciones del archivo S0211-69952009000600009.xml 14 Media de oraciones actual: 10.833333333333334\n",
            "Número de oraciones del archivo S0211-69952009000600014.xml 10 Media de oraciones actual: 10.8\n",
            "El archivo con menos oraciones es: S0211-69952009000500015.xml con 2\n",
            "El archivo con más oraciones es: S0211-69952009000500008.xmlcon 26 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NehqwQRAhnWI"
      },
      "source": [
        "### Ejercicio 2\n",
        "\n",
        "Crear un programa que divida en oraciones los textos presentes en él. Posteriormente, realize una tokenización de las palabras haciendo uso de la clase *WordPunctTokenizer*. Finalmente, la función debe mostrar el número medio de palabras por fichero, el fichero que contiene menos palabras y el fichero que contiene más palabras."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import wordpunct_tokenize\n",
        "oraciones=[]   #Vector auxiliar para almacenar las oraciones de cada archivo tras tokenizar\n",
        "numPalabras=[] #Vector para guardar el número de palabras de cada archivo\n",
        "i=0\n",
        "menor=2000\n",
        "mayor=-10\n",
        "indiceMayor=0\n",
        "indiceMenor=0\n",
        "numOraciones=[]  #Vector para guardar el número de oraciones de cada archivo\n",
        "media=0\n",
        "for archivo in archivosProcesados:\n",
        "  oraciones=sent_tokenize(archivo, language=\"spanish\") #Tokenizamos en oraciones y la guardamos en el vector auxiliar de oraciones del archivo\n",
        "  sumaPalabras=0\n",
        "  j=0\n",
        "  for oracion in oraciones: #Tokenizamos todas las oraciones de este archivo en palabras y contamos mediante una suma el número de palabras\n",
        "    sumaPalabras=sumaPalabras+len(wordpunct_tokenize(oracion))\n",
        "    j=j+1\n",
        "  numPalabras.append(sumaPalabras)\n",
        "  media=sumaPalabras/j  #Media de palabras por oracion de cada archivo\n",
        "  print(\"Número de palabras del archivo\",end=\" \")\n",
        "  print(nombresArchivos[i],end=\" \")\n",
        "  print(sumaPalabras,end=\" \")\n",
        "  print(\"Media del archivo:\",end=\" \")\n",
        "  print(media)\n",
        "  if sumaPalabras<menor: #Calculamos el archivo con más o menos palabras y almacenamos sus índices\n",
        "    menor=sumaPalabras\n",
        "    indiceMenor=i\n",
        "  \n",
        "  if sumaPalabras>mayor:\n",
        "    mayor=sumaPalabras\n",
        "    indiceMayor=i\n",
        "\n",
        "  i=i+1\n",
        "\n",
        "print(\"El archivo con menos palabras es: \",end=\"\")\n",
        "print(nombresArchivos[indiceMenor],end=\"\")\n",
        "print(\" con\",end=\" \")\n",
        "print(menor)\n",
        "\n",
        "print(\"El archivo con más palabras es: \",end=\"\")\n",
        "print(nombresArchivos[indiceMayor],end=\"\")\n",
        "print(\"con\",end=\" \")\n",
        "print(mayor,end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dPl5fOXVr90",
        "outputId": "b7c824bc-8595-44ce-8b48-8f99f21da34e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de palabras del archivo S0211-69952009000500011.xml 346 Media del archivo: 23.066666666666666\n",
            "Número de palabras del archivo S0211-69952009000600003.xml 255 Media del archivo: 25.5\n",
            "Número de palabras del archivo S0211-69952009000600011.xml 328 Media del archivo: 32.8\n",
            "Número de palabras del archivo S0211-69952010000100007.xml 614 Media del archivo: 32.31578947368421\n",
            "Número de palabras del archivo S0211-69952009000600010.xml 302 Media del archivo: 25.166666666666668\n",
            "Número de palabras del archivo S0211-69952009000500014.xml 148 Media del archivo: 24.666666666666668\n",
            "Número de palabras del archivo S0211-69952009000500007.xml 415 Media del archivo: 37.72727272727273\n",
            "Número de palabras del archivo S0211-69952009000500008.xml 705 Media del archivo: 27.115384615384617\n",
            "Número de palabras del archivo S0211-69952009000600012.xml 516 Media del archivo: 39.69230769230769\n",
            "Número de palabras del archivo S0211-69952009000500009.xml 278 Media del archivo: 25.272727272727273\n",
            "Número de palabras del archivo S0211-69952009000500013.xml 221 Media del archivo: 27.625\n",
            "Número de palabras del archivo S0211-69952009000500002.xml 147 Media del archivo: 29.4\n",
            "Número de palabras del archivo S0211-69952009000600013.xml 335 Media del archivo: 37.22222222222222\n",
            "Número de palabras del archivo S0211-69952010000100004.xml 179 Media del archivo: 35.8\n",
            "Número de palabras del archivo S0211-69952010000100006.xml 184 Media del archivo: 36.8\n",
            "Número de palabras del archivo S0211-69952010000100008.xml 459 Media del archivo: 35.30769230769231\n",
            "Número de palabras del archivo S0211-69952009000500006.xml 423 Media del archivo: 38.45454545454545\n",
            "Número de palabras del archivo S0211-69952009000600006.xml 122 Media del archivo: 20.333333333333332\n",
            "Número de palabras del archivo S0211-69952009000600004.xml 146 Media del archivo: 24.333333333333332\n",
            "Número de palabras del archivo S0211-69952009000500010.xml 352 Media del archivo: 19.555555555555557\n",
            "Número de palabras del archivo S0211-69952009000500015.xml 38 Media del archivo: 19.0\n",
            "Número de palabras del archivo S0211-69952009000600015.xml 120 Media del archivo: 30.0\n",
            "Número de palabras del archivo S0211-69952009000500012.xml 570 Media del archivo: 27.142857142857142\n",
            "Número de palabras del archivo S0211-69952009000600009.xml 311 Media del archivo: 22.214285714285715\n",
            "Número de palabras del archivo S0211-69952009000600014.xml 296 Media del archivo: 29.6\n",
            "El archivo con menos palabras es: S0211-69952009000500015.xml con 38\n",
            "El archivo con más palabras es: S0211-69952009000500008.xmlcon 705 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUey1NQvjBvt"
      },
      "source": [
        "### Ejercicio 3\n",
        "\n",
        "Dividir en tokens la oración que se muestra a continuación empleando los siguientes tokenizadores: “TreebankWordTokenizer”, \"WhitespaceTokenizer”, “SpaceTokenizer” y \"WordPunctTokenizer”. \n",
        "\n",
        "¿Qué diferencias se observan en la salida producida por cada uno de\n",
        "ellos?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "EU0N3R4PjWdK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788b43a2-c9d1-4a49-cd5f-ea115a9a77b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sorry', ',', 'I', 'ca', \"n't\", 'go', 'to', 'the', 'meeting', '.']\n",
            "['Sorry,', 'I', \"can't\", 'go', 'to', 'the', 'meeting.']\n",
            "['Sorry,', 'I', \"can't\", 'go', 'to', 'the', 'meeting.\\n']\n",
            "['Sorry', ',', 'I', 'can', \"'\", 't', 'go', 'to', 'the', 'meeting', '.']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Sorry, I can't go to the meeting.\\n\"\n",
        "\n",
        "from nltk.tokenize import TreebankWordTokenizer\n",
        "\n",
        "print(TreebankWordTokenizer().tokenize(sentence))\n",
        "\n",
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "print(WhitespaceTokenizer().tokenize(sentence))\n",
        "\n",
        "from nltk.tokenize import SpaceTokenizer\n",
        "\n",
        "print(SpaceTokenizer().tokenize(sentence))\n",
        "\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "\n",
        "print(WordPunctTokenizer().tokenize(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Diferencias:**\n",
        "- El TreebankWordTokenizer tokeniza los signos de puntuación y además separa la raiz (ca) y la contracción de la negación del verbo can (n't).\n",
        "- El WhitespaceTokenizer tokeniza los signos de puntuación y no separa el verbo can't.\n",
        "- El SpaceTokenizer no tokeniza los signos de puntuación pero los comandos de carácteres los trata como parte de la palabra.\n",
        "- El WordPunctTokenizer tokeniza los signos de puntuación y el verbo can't lo separa en can, ' y t.\n"
      ],
      "metadata": {
        "id": "u4SjiMeTgdyC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8JoaOaIjmGD"
      },
      "source": [
        "### Ejercicio 4\n",
        "\n",
        "Crear un tokenizador basado en expresiones regulares usando la clase *RegexpTokenizer* de NLTK que extraiga sólo las palabras presentes en el texto, es decir, que no devuelva como salida los signos de puntuación ni los tabuladores/saltos de línea, etc.\n",
        "\n",
        "Además, el tokenizador no deberá separar las contracciones del texto.\n",
        "\n",
        "¿Cuáles son los tokens extraídos si le pasamos la siguiente oración?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JjM1NQs1jy8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb9b463d-6789-416e-89f5-029e0d6369c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sorry', 'I', 'can', 't', 'go', 'to', 'the', 'meeting']\n"
          ]
        }
      ],
      "source": [
        "sentence = \"Sorry, I can't, go to the meeting.\\n\"\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "print(RegexpTokenizer(r'\\w+').tokenize(sentence))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokens extraidos:** Sorry, I, can, t, go, to, the y meeting"
      ],
      "metadata": {
        "id": "KrKFrbETl6LR"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}